{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Probabilistic Attempt with Pangu Weather (!! Actually not!! )\n",
    "### For the ML based probabilistic models that WeatherBench 2 has (Pangu, Fuxi), it doesn't have ensemble forecasts for them?\n",
    "### Only ensemble forecaster to test on is the ECMWF IFS ENS model (Physical numerically based)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import weatherbench2\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import math\n",
    "from weatherbench2.regions import SliceRegion, ExtraTropicalRegion\n",
    "from weatherbench2.evaluation import evaluate_in_memory\n",
    "from weatherbench2 import config\n",
    "from weatherbench2.metrics import CRPS, CRPSSpread, CRPSSkill, EnsembleVariance, EnsembleMeanMSE, EnsembleIgnoranceScore, EnsembleBrierScore, EnergyScore, EnergyScoreSkill, EnergyScoreSpread, RankHistogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_path = 'gs://weatherbench2/datasets/ifs_ens/2018-2022-64x32_equiangular_conservative.zarr'\n",
    "obs_path = 'gs://weatherbench2/datasets/era5/1959-2022-6h-64x32_equiangular_conservative.zarr'\n",
    "climatology_path = 'gs://weatherbench2/datasets/era5-hourly-climatology/1990-2019_6h_64x32_equiangular_conservative.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "climatology = xr.open_zarr(climatology_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = xr.open_zarr(forecast_path)\n",
    "observations = xr.open_zarr(obs_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = forecasts['geopotential'].sel(level = 500, time = slice('2020-01-01', '2020-12-31'))\n",
    "ensembledim = test[0,:,0,0,0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths1 = config.Paths(\n",
    "    forecast=forecast_path,\n",
    "    obs=obs_path,\n",
    "    output_dir='./',   # Directory to save evaluation results\n",
    ")\n",
    "\n",
    "selection1 = config.Selection(\n",
    "    variables=[\n",
    "        'geopotential',\n",
    "    ],\n",
    "    levels=[500],\n",
    "    time_slice=slice('2020-01-01', '2020-2-01'),\n",
    ")\n",
    "\n",
    "data_config1 = config.Data(selection=selection1, paths=paths1)\n",
    "\n",
    "regions1 = {\n",
    "    'global': SliceRegion(),\n",
    "}\n",
    "\n",
    "eval_configs1 = {\n",
    "  'SpreadandSkill': config.Eval(\n",
    "      metrics={\n",
    "          #'CRPS': CRPS('number'),\n",
    "          'CRPSSpread': CRPSSpread('number'),\n",
    "          'CRPSSkill': CRPSSkill('number'),\n",
    "          #'EnsembleVariance': EnsembleVariance('number'),\n",
    "          #'EnsembleMeanMSE': EnsembleMeanMSE('number'),\n",
    "          #'EnsembleIgnoranceScore': EnsembleIgnoranceScore('number'),\n",
    "          #'EnsembleBrierScore': EnsembleBrierScore('number'),\n",
    "          #'EnergyScore': EnergyScore('number'),\n",
    "          #'EnergyScoreSkill': EnergyScoreSkill('number'),\n",
    "          #'EnergyScoreSpread': EnergyScoreSpread('number'),\n",
    "          #'RankHistogram': RankHistogram('number', 40),\n",
    "      },\n",
    "      regions=regions1\n",
    "  )\n",
    "}\n",
    "\n",
    "\n",
    "evaluate_in_memory(data_config1, eval_configs1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = xr.open_dataset('./OnlyEnergyScore.nc')\n",
    "mini = xr.open_dataset('./OnlyEnergyScoreMini.nc')\n",
    "crpsmini = xr.open_dataset('./OnlyCRPSMini.nc')\n",
    "spreadskill = xr.open_dataset('./SpreadandSkill.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 16.40059168],\n",
       "         [ 17.37380748],\n",
       "         [ 21.90202082],\n",
       "         [ 22.90374028],\n",
       "         [ 28.63360494],\n",
       "         [ 31.81376322],\n",
       "         [ 39.01819658],\n",
       "         [ 44.04651572],\n",
       "         [ 51.68230127],\n",
       "         [ 57.91323458],\n",
       "         [ 67.29016766],\n",
       "         [ 74.74342197],\n",
       "         [ 85.50607702],\n",
       "         [ 94.58680874],\n",
       "         [106.54174907],\n",
       "         [116.78540843],\n",
       "         [130.36353479],\n",
       "         [141.70619667],\n",
       "         [156.08422899],\n",
       "         [168.37324771],\n",
       "         [183.27989723],\n",
       "         [195.86959851],\n",
       "         [211.10127055],\n",
       "         [224.03251049],\n",
       "         [239.35082032],\n",
       "         [252.27782218],\n",
       "         [267.28129823],\n",
       "         [279.85692916],\n",
       "         [294.38048833],\n",
       "         [306.46043771],\n",
       "         [320.08435552],\n",
       "         [331.38892106],\n",
       "         [344.09150722],\n",
       "         [354.43868065],\n",
       "         [366.01286461],\n",
       "         [375.52007359],\n",
       "         [386.0933858 ],\n",
       "         [394.6009482 ],\n",
       "         [404.27010527],\n",
       "         [411.86879601],\n",
       "         [420.51416921],\n",
       "         [427.15605819],\n",
       "         [434.87388042],\n",
       "         [440.56451644],\n",
       "         [447.48825687],\n",
       "         [452.3856456 ],\n",
       "         [458.54752612],\n",
       "         [462.78693742],\n",
       "         [468.45115528],\n",
       "         [472.17231507],\n",
       "         [477.39624719],\n",
       "         [480.78178004],\n",
       "         [485.6151637 ],\n",
       "         [488.5331647 ],\n",
       "         [493.01033225],\n",
       "         [495.50886922],\n",
       "         [499.56174259],\n",
       "         [501.68003894],\n",
       "         [505.40380656],\n",
       "         [507.20823051],\n",
       "         [510.76306216]]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini['geopotential'][:,:,:,:].values\n",
    "full['geopotential'][:,:,:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 15.39833045],\n",
       "         [ 13.90813641],\n",
       "         [ 18.48164672],\n",
       "         [ 18.79502823],\n",
       "         [ 23.33586116],\n",
       "         [ 25.09675912],\n",
       "         [ 29.79921545],\n",
       "         [ 32.66286534],\n",
       "         [ 37.49048854],\n",
       "         [ 40.74957466],\n",
       "         [ 46.30516335],\n",
       "         [ 50.02635873],\n",
       "         [ 56.65534858],\n",
       "         [ 61.21588492],\n",
       "         [ 69.04774343],\n",
       "         [ 73.62024404],\n",
       "         [ 82.33203342],\n",
       "         [ 87.12597117],\n",
       "         [ 96.89399812],\n",
       "         [101.96509481],\n",
       "         [112.14784674],\n",
       "         [117.16877823],\n",
       "         [127.53752385],\n",
       "         [133.17227312],\n",
       "         [143.99448775],\n",
       "         [149.5352887 ],\n",
       "         [160.33624455],\n",
       "         [166.31286538],\n",
       "         [176.7369237 ],\n",
       "         [182.8505406 ],\n",
       "         [192.72160336],\n",
       "         [198.78255656],\n",
       "         [208.19766894],\n",
       "         [214.02217448],\n",
       "         [222.52567799],\n",
       "         [228.39327023],\n",
       "         [236.27860973],\n",
       "         [241.77518914],\n",
       "         [248.94896831],\n",
       "         [254.17263142],\n",
       "         [260.71416555],\n",
       "         [265.37037943],\n",
       "         [271.04194019],\n",
       "         [274.99604607],\n",
       "         [280.189976  ],\n",
       "         [283.84200309],\n",
       "         [288.84266277],\n",
       "         [292.13281746],\n",
       "         [296.78708544],\n",
       "         [299.29864948],\n",
       "         [303.187527  ],\n",
       "         [305.07273827],\n",
       "         [308.88324015],\n",
       "         [310.53490499],\n",
       "         [314.06829058],\n",
       "         [315.31972148],\n",
       "         [318.86485842],\n",
       "         [320.26352304],\n",
       "         [323.67694951],\n",
       "         [324.83076675],\n",
       "         [327.964989  ]]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crpsmini['geopotential'][:,:,:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 23.73866304]\n",
      "  [ 23.90021249]\n",
      "  [ 30.91322866]\n",
      "  [ 34.05420002]\n",
      "  [ 42.00982705]\n",
      "  [ 47.46495631]\n",
      "  [ 56.17729284]\n",
      "  [ 63.13925993]\n",
      "  [ 72.27117911]\n",
      "  [ 80.0075033 ]\n",
      "  [ 90.22649832]\n",
      "  [ 98.77403801]\n",
      "  [110.4483304 ]\n",
      "  [120.3977575 ]\n",
      "  [133.85186203]\n",
      "  [144.30469093]\n",
      "  [159.08652682]\n",
      "  [170.19169643]\n",
      "  [186.51491316]\n",
      "  [198.39449839]\n",
      "  [215.58971092]\n",
      "  [227.77626476]\n",
      "  [245.4786898 ]\n",
      "  [258.54356641]\n",
      "  [276.92603696]\n",
      "  [290.1243808 ]\n",
      "  [308.71052312]\n",
      "  [322.39835119]\n",
      "  [340.54700531]\n",
      "  [354.34626372]\n",
      "  [371.89054464]\n",
      "  [385.48179663]\n",
      "  [402.24125238]\n",
      "  [415.18946598]\n",
      "  [430.66399729]\n",
      "  [443.29428707]\n",
      "  [457.68082197]\n",
      "  [469.427438  ]\n",
      "  [482.65964666]\n",
      "  [493.65758194]\n",
      "  [505.76101657]\n",
      "  [515.75075475]\n",
      "  [526.55196781]\n",
      "  [535.46755852]\n",
      "  [545.40918455]\n",
      "  [553.58284309]\n",
      "  [562.9220238 ]\n",
      "  [570.3904321 ]\n",
      "  [579.03124833]\n",
      "  [585.38735445]\n",
      "  [592.98249733]\n",
      "  [598.39624532]\n",
      "  [605.58963884]\n",
      "  [610.42218369]\n",
      "  [617.00861506]\n",
      "  [621.13669276]\n",
      "  [627.43843726]\n",
      "  [631.36723003]\n",
      "  [637.2948839 ]\n",
      "  [640.7327922 ]\n",
      "  [646.09537709]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 16.68066519],\n",
       "        [ 19.98415216],\n",
       "        [ 24.86316387],\n",
       "        [ 30.51834358],\n",
       "        [ 37.34793178],\n",
       "        [ 44.73639437],\n",
       "        [ 52.75615478],\n",
       "        [ 60.95278919],\n",
       "        [ 69.56138113],\n",
       "        [ 78.51585729],\n",
       "        [ 87.84266995],\n",
       "        [ 97.49535857],\n",
       "        [107.58596364],\n",
       "        [118.36374517],\n",
       "        [129.60823719],\n",
       "        [141.36889377],\n",
       "        [153.5089868 ],\n",
       "        [166.13145052],\n",
       "        [179.24183006],\n",
       "        [192.85880715],\n",
       "        [206.88372837],\n",
       "        [221.21497306],\n",
       "        [235.8823319 ],\n",
       "        [250.74258659],\n",
       "        [265.86309841],\n",
       "        [281.1781842 ],\n",
       "        [296.74855714],\n",
       "        [312.17097162],\n",
       "        [327.62016324],\n",
       "        [342.99144624],\n",
       "        [358.33788257],\n",
       "        [373.39848015],\n",
       "        [388.0871669 ],\n",
       "        [402.334583  ],\n",
       "        [416.27663858],\n",
       "        [429.80203369],\n",
       "        [442.80442446],\n",
       "        [455.30449773],\n",
       "        [467.4213567 ],\n",
       "        [478.96990104],\n",
       "        [490.09370205],\n",
       "        [500.76075065],\n",
       "        [511.02005525],\n",
       "        [520.9430249 ],\n",
       "        [530.43841711],\n",
       "        [539.48167999],\n",
       "        [548.15872206],\n",
       "        [556.5152293 ],\n",
       "        [564.48832579],\n",
       "        [572.17740995],\n",
       "        [579.58994067],\n",
       "        [586.64701409],\n",
       "        [593.41279739],\n",
       "        [599.7745574 ],\n",
       "        [605.88064895],\n",
       "        [611.63394255],\n",
       "        [617.14715768],\n",
       "        [622.20741397],\n",
       "        [627.23586879],\n",
       "        [631.8040509 ],\n",
       "        [636.26077619]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill = spreadskill['geopotential'].sel(metric = 'CRPSSkill')\n",
    "spread = spreadskill['geopotential'].sel(metric = 'CRPSSpread')\n",
    "\n",
    "#print(skill.values-spread/2)\n",
    "print(skill.values)\n",
    "spread.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07704437, 0.23039114, 0.38151911, 0.52897285, 0.67133229,\n",
       "       0.80722643, 0.93534654, 1.05445875, 1.16341595, 1.26116882,\n",
       "       1.34677594, 1.41941287, 1.47838008, 1.52310968, 1.55317091,\n",
       "       1.56827425, 1.56827425, 1.55317091, 1.52310968, 1.47838008,\n",
       "       1.41941287, 1.34677594, 1.26116882, 1.16341595, 1.05445875,\n",
       "       0.93534654, 0.80722643, 0.67133229, 0.52897285, 0.38151911,\n",
       "       0.23039114, 0.07704437])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latitude = forecasts['latitude'][:].values\n",
    "delta = 2.8125\n",
    "theta_upper = latitude + delta\n",
    "theta_lower = latitude - delta\n",
    "\n",
    "# Calculate weights based on the provided formula\n",
    "weights = (np.sin(np.radians(theta_upper)) - np.sin(np.radians(theta_lower)))\n",
    "weights /= weights.sum()\n",
    "weights *= 32\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(23.73866304),\n",
       " array(23.90021249),\n",
       " array(30.91322866),\n",
       " array(34.05420002),\n",
       " array(42.00982705),\n",
       " array(47.46495631),\n",
       " array(56.17729284),\n",
       " array(63.13925993),\n",
       " array(72.27117911),\n",
       " array(80.00750331),\n",
       " array(90.22649833),\n",
       " array(98.77403801),\n",
       " array(110.44833038),\n",
       " array(120.39775749),\n",
       " array(133.85186204),\n",
       " array(144.30469092),\n",
       " array(159.08652681),\n",
       " array(170.19169643),\n",
       " array(186.51491313),\n",
       " array(198.39449838),\n",
       " array(215.58971091),\n",
       " array(227.77626475),\n",
       " array(245.47868984),\n",
       " array(258.54356644),\n",
       " array(276.92603697),\n",
       " array(290.12438084),\n",
       " array(308.71052315),\n",
       " array(322.39835109),\n",
       " array(340.54700529),\n",
       " array(354.34626371),\n",
       " array(371.89054462),\n",
       " array(385.48179658),\n",
       " array(402.24125224),\n",
       " array(415.18946574),\n",
       " array(430.66399708),\n",
       " array(443.29428712),\n",
       " array(457.68082199),\n",
       " array(469.42743805),\n",
       " array(482.65964672),\n",
       " array(493.65758205),\n",
       " array(505.7610166),\n",
       " array(515.75075474),\n",
       " array(526.55196797),\n",
       " array(535.46755875),\n",
       " array(545.40918452),\n",
       " array(553.58284313),\n",
       " array(562.9220239),\n",
       " array(570.39043206),\n",
       " array(579.03124812),\n",
       " array(585.38735445),\n",
       " array(592.98249734),\n",
       " array(598.39624532),\n",
       " array(605.58963895),\n",
       " array(610.42218394),\n",
       " array(617.00861506),\n",
       " array(621.13669231),\n",
       " array(627.43843716),\n",
       " array(631.36723013),\n",
       " array(637.29488369),\n",
       " array(640.73279245),\n",
       " array(646.09537708)]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing on Mini, code not generalised\n",
    "\n",
    "#15 extra days lead\n",
    "a = forecasts['geopotential'].sel(level = 500, time = slice('2020-01-01', '2020-02-01'))[:,:,:,:]\n",
    "b = observations['geopotential'].sel(level=500, time = slice('2020-01-01', '2020-02-16'))[:,:,:]\n",
    "\n",
    "#Skill\n",
    "skills = []\n",
    "for i in range(61):\n",
    "    ashifted = a.assign_coords(time = a.time + a[:,:,i,:,:]['prediction_timedelta'].values)\n",
    "    if (i ==60):\n",
    "        vals = np.sum(abs(ashifted[:,:,i,:,:]-b[i:,:,:][::2,:,:]) *weights[None,None,:], axis = (0,1,2,3))/(64*50*64*32)\n",
    "    else:\n",
    "        vals = np.sum(abs(ashifted[:,:,i,:,:]-b[i:i-60,:,:][::2,:,:]) *weights[None,None,:], axis = (0,1,2,3))/(64*50*64*32)\n",
    "    skills.append(vals.values)\n",
    "\n",
    "skills\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Page 12 of WeatherBench 2 paper suggests more efficient way to calculate E[X-X'], using loops, not done here. \n",
    "#Spread \n",
    "\n",
    "Spreads = []\n",
    "\n",
    "for i in range(61):\n",
    "    ashifted = a.assign_coords(time = a.time + a[:,:,i,:,:]['prediction_timedelta'].values)\n",
    "    if (i ==60):\n",
    "        vals = np.sum(abs(ashifted[:,:,i,:,:]-b[i:,:,:][::2,:,:]) *weights[None,None,:], axis = (0,1,2,3))/(64*50*64*32)\n",
    "    else:\n",
    "        vals = np.sum(abs(ashifted[:,:,i,:,:]-b[i:i-60,:,:][::2,:,:]) *weights[None,None,:], axis = (0,1,2,3))/(64*50*64*32)\n",
    "    Spreads.append(vals.values)\n",
    "\n",
    "skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Page 12 of WeatherBench 2 paper suggests more efficient way to calculate E[X-X'], using loops, not done here. \n",
    "#However, this loop method for just lag 0 takes 6 minutes.\n",
    "#\n",
    "# Spread \n",
    "#\n",
    "\n",
    "a = forecasts['geopotential'].sel(level = 500, time = slice('2020-01-01', '2020-02-01'))[:,:,:,:]\n",
    "weighted_abs_differences = xr.zeros_like((abs(a[:, 0,0, :, :] - a[:, 1,0, :, :]) * weights[None,None,:]))\n",
    "\n",
    "for m in range(50):\n",
    "    for n in range(50):\n",
    "        if m != n:\n",
    "            weighted_abs = abs(a[:, m,0, :, :] - a[:, n,0, :, :]) * weights[None,None,:]\n",
    "            weighted_abs_differences += weighted_abs\n",
    "\n",
    "\n",
    "final_metric = np.sum(weighted_abs_differences) / (50*(50 - 1)*64*64*32)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(16.68066519)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Takes ~6 Minutes to run, but does calculate spread correctly... \n",
    "final_metric.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Have had some work with probabilistic diagnostics, but time demands are increasing. Going to try experimenting with sigkernel now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sigkernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0042, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the static kernel (for linear kernel use sigkernel.LinearKernel())\n",
    "static_kernel = sigkernel.RBFKernel(sigma=2)\n",
    "\n",
    "# Specify dyadic order for PDE solver (int > 0, default 0, the higher the more accurate but slower)\n",
    "dyadic_order = 1\n",
    "\n",
    "# Specify maximum batch size of computation; if memory is a concern try reducing max_batch, default=100\n",
    "max_batch = 100\n",
    "\n",
    "# Initialize the corresponding signature kernel\n",
    "signature_kernel = sigkernel.SigKernel(static_kernel, dyadic_order)\n",
    "\n",
    "# Synthetic data\n",
    "batch, len_x, len_y, dim = 5, 10, 20, 2\n",
    "X = torch.rand((batch,len_x,dim), dtype=torch.float64, device='cuda') # shape (batch,len_x,dim)\n",
    "Y = torch.rand((batch,len_y,dim), dtype=torch.float64, device='cuda') # shape (batch,len_y,dim)\n",
    "Z = torch.rand((batch,len_x,dim), dtype=torch.float64, device='cuda') # shape (batch,len_y,dim)\n",
    "\n",
    "\n",
    "\n",
    "# Compute signature kernel \"batch-wise\" (i.e. k(x_1,y_1),...,k(x_batch, y_batch))\n",
    "K = signature_kernel.compute_kernel(X,Y,max_batch)\n",
    "\n",
    "# Compute signature kernel Gram matrix (i.e. k(x_i,y_j) for i,j=1,...,batch), also works for different batch_x != batch_y)\n",
    "G = signature_kernel.compute_Gram(X,Y,max_batch)\n",
    "\n",
    "G\n",
    "# Compute MMD distance between samples x ~ X and samples y ~ Y, where X,Y are two distributions on path space...\n",
    "mmd = signature_kernel.compute_mmd(X,Y,max_batch)\n",
    "\n",
    "mmd\n",
    "# # ... and to backpropagate through the MMD distance simply call .backward(), like any other PyTorch loss function\n",
    "#mmd.backward()\n",
    "\n",
    "# # Compute scoring rule between X and a sample path y, i.e. S_sig(X,y) = E[k(X,X)] - 2E[k(X,y] ...\n",
    "# y = Y[0]\n",
    "# sr = signature_kernel.compute_scoring_rule(X,y,max_batch)\n",
    "\n",
    "# # ... and expected scoring rule between X and Y, i.e. S(X,Y) = E_Y[S_sig(X,y)]\n",
    "# esr = signature_kernel.compute_expected_scoring_rule(X,Y,max_batch)\n",
    "\n",
    "# # Sig CHSIC: XY|Z\n",
    "# sigchsic = signature_kernel.SigCHSIC(X, Y, Z, static_kernel, dyadic_order=1, eps=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arche\\anaconda3\\envs\\Diss\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 5 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\arche\\anaconda3\\envs\\Diss\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 25 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[291], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m mmd \u001b[38;5;241m=\u001b[39m signature_kernel\u001b[38;5;241m.\u001b[39mcompute_mmd(X,Y,max_batch)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# ... and to backpropagate through the MMD distance simply call .backward(), like any other PyTorch loss function\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[43mmmd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m mmd\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# # Compute scoring rule between X and a sample path y, i.e. S_sig(X,y) = E[k(X,X)] - 2E[k(X,y] ...\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arche\\anaconda3\\envs\\Diss\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\arche\\anaconda3\\envs\\Diss\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\arche\\anaconda3\\envs\\Diss\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sigkernel\n",
    "\n",
    "# Specify the static kernel (for linear kernel use sigkernel.LinearKernel())\n",
    "static_kernel = sigkernel.RBFKernel(sigma=1.5)\n",
    "\n",
    "# Specify dyadic order for PDE solver (int > 0, default 0, the higher the more accurate but slower)\n",
    "dyadic_order = 2\n",
    "\n",
    "# Specify maximum batch size of computation; if memory is a concern try reducing max_batch, default=100\n",
    "max_batch = 100\n",
    "\n",
    "# Initialize the corresponding signature kernel\n",
    "signature_kernel = sigkernel.SigKernel(static_kernel, dyadic_order)\n",
    "\n",
    "# Synthetic data\n",
    "batch, len_x, len_y, dim = 5, 10, 20, 2\n",
    "X = torch.rand((batch,len_x,dim), dtype=torch.float64, device='cuda') # shape (batch,len_x,dim)\n",
    "Y = torch.rand((batch,len_y,dim), dtype=torch.float64, device='cuda') # shape (batch,len_y,dim)\n",
    "Z = torch.rand((batch,len_x,dim), dtype=torch.float64, device='cuda') # shape (batch,len_y,dim)\n",
    "\n",
    "# Compute signature kernel \"batch-wise\" (i.e. k(x_1,y_1),...,k(x_batch, y_batch))\n",
    "K = signature_kernel.compute_kernel(X,Y,max_batch)\n",
    "\n",
    "# Compute signature kernel Gram matrix (i.e. k(x_i,y_j) for i,j=1,...,batch), also works for different batch_x != batch_y)\n",
    "G = signature_kernel.compute_Gram(X,Y,sym=False)\n",
    "\n",
    "# Compute MMD distance between samples x ~ X and samples y ~ Y, where X,Y are two distributions on path space...\n",
    "mmd = signature_kernel.compute_mmd(X,Y,max_batch)\n",
    "# ... and to backpropagate through the MMD distance simply call .backward(), like any other PyTorch loss function\n",
    "mmd.backward()\n",
    "\n",
    "mmd\n",
    "# # Compute scoring rule between X and a sample path y, i.e. S_sig(X,y) = E[k(X,X)] - 2E[k(X,y] ...\n",
    "y = Y[0]\n",
    "\n",
    "sr = signature_kernel.compute_scoring_rule(X,y,max_batch)\n",
    "\n",
    "# # ... and expected scoring rule between X and Y, i.e. S(X,Y) = E_Y[S_sig(X,y)]\n",
    "# esr = signature_kernel.compute_expected_scoring_rule(X,Y,max_batch)\n",
    "\n",
    "# # Sig CHSIC: XY|Z\n",
    "# sigchsic = signature_kernel.SigCHSIC(X, Y, Z, static_kernel, dyadic_order=1, eps=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Diss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
