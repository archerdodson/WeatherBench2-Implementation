{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import gamma\n",
    "from scipy.stats import expon\n",
    "from scipy.stats import binom\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Designing scoring rules sampling on gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.4265498   1.27965825  1.89078308 -0.66636748  0.72909906  1.65086434\n",
      " -0.47101462  1.21869074  1.1886383   2.94490197]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "data_normal = norm.rvs(size=1000, loc=0, scale = 1)\n",
    "\n",
    "# Creating a couple potential distributions to compare with\n",
    "normal1 = norm(loc=0, scale = 1)\n",
    "normal2 = norm(loc=1, scale = 1)\n",
    "normal3 = norm(loc=0, scale = 2)\n",
    "binom1 = binom(n=2,p=0.5)\n",
    "\n",
    "\n",
    "#print(data_normal)\n",
    "print(normal1.rvs(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy Score\n",
    "$\\textnormal{Energy Score} (F,x) = 2E_F[||X-x||] - E_F[||X-X'||]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First example of energy score is when distribution is constant\n",
    "#1 dimensional data\n",
    "def energyscore1(samples, predist):\n",
    "\n",
    "    # sample to true \n",
    "    M=samples.size\n",
    "    distsamples = predist.rvs(M)\n",
    "\n",
    "    E1 = sum(abs(distsamples - samples))/M\n",
    "    #pairs of samples to itself\n",
    "    #print(distsamples - distsamples.reshape(-1,1))\n",
    "    E2 = np.sum(abs(distsamples - distsamples.reshape(-1,1)))/(M*(M-1))  ##This line is bad storage wise\n",
    "\n",
    "    score = 2*E1 - E2\n",
    "    print(score)\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7606140733487035\n",
      "2.4228473886883832\n",
      "2.5252476974745433\n",
      "2.634777664467761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(2.634777664467761)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Testing on different distributions\n",
    "data_normaltest = norm.rvs(size=1000, loc=1, scale = 2)\n",
    "\n",
    "#\n",
    "energyscore1(data_normaltest, normal1)\n",
    "energyscore1(data_normaltest, normal2)\n",
    "energyscore1(data_normaltest, normal3)\n",
    "energyscore1(data_normaltest, binom1)\n",
    "\n",
    "#distribution closest does have lowest energy score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second example is when you have pairs of different distributions and samples\n",
    "#Assuming # of samples is equivalent to number of distributions\n",
    "def energyscore2(samples, dists):\n",
    "\n",
    "    # sample to true \n",
    "    M=samples.size\n",
    "    distsamples = norm.rvs(loc=dists[:,0], scale = dists[:,1])\n",
    "\n",
    "    E1 = sum(abs(distsamples - samples))/M\n",
    "    #pairs of samples to itself\n",
    "    E2 = np.sum(abs(distsamples - distsamples.reshape(-1,1)))/(M*(M-1))  ##This line is bad storage wise\n",
    "\n",
    "    score = 2*E1 - E2\n",
    "    print(score)\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.289224841605872\n",
      "2.218217087923419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(2.218217087923419)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normaltest = norm.rvs(size=1000, loc=1, scale = 2)\n",
    "\n",
    "#Creating sequences of distributions (mean 0:1, scale 1:2) for guassian distributions.\n",
    "locs = uniform.rvs(loc=0, scale=1, size =1000)\n",
    "scales = uniform.rvs(loc =1, scale =1, size = 1000)\n",
    "params1 = np.column_stack((locs,scales))\n",
    "\n",
    "\n",
    "# creating sequences of distributions, (mean 0.5:1.5, scale 1:2)\n",
    "locs = uniform.rvs(loc=0.5, scale=1, size =1000)\n",
    "scales = uniform.rvs(loc =1, scale =1, size = 1000)\n",
    "params2 = np.column_stack((locs,scales))\n",
    "\n",
    "\n",
    "energyscore2(data_normaltest, params1)\n",
    "energyscore2(data_normaltest, params2) #better most times as mean is closer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEEPS\n",
    "Making example data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140.0\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Okay forecasting, 50% dry correct, 100% light correct, 80% heavy correct\n",
    "contingency1 = [[50,0,0],[50,50,10],[0,0,40]]\n",
    "#Fully correct forecast for same observation\n",
    "contingency2 = [[100,0,0],[0,50,0],[0,0,50]]\n",
    "\n",
    "#probability of D, L, H 0.5, 0.25, 0.25\n",
    "\n",
    "S = [[0,2,6],[2,0,4],[10/3,4/3,0]]\n",
    "\n",
    "def SEEPS(cont, score):\n",
    "    mult = np.multiply(cont, score)\n",
    "    sums = mult.sum()\n",
    "\n",
    "    print(sums)\n",
    "    return(sums)\n",
    "\n",
    "\n",
    "#SEEPS(contingency1,S)\n",
    "#SEEPS(contingency2,S)\n",
    "\n",
    "#Perfect forecast has SEEPS of 0\n",
    "#Can see how scoring matrix weights difference between dry and heavy much more heavily. \n",
    "\n",
    "def SEEPSfull(cont):\n",
    "    col_sums = np.sum(cont, axis = 0)\n",
    "    total_events = col_sums.sum()\n",
    "    pD = col_sums[0]/total_events\n",
    "    pL = col_sums[1]/total_events #not used\n",
    "    pH = col_sums[2]/total_events\n",
    "\n",
    "    S = [[0,1/pD,1/pH + 1/(1-pD)],[1/pD,0,1/pH],[1/pD + 1/(1-pH), 1/(1-pH), 0]]\n",
    "\n",
    "    mult = np.multiply(cont, S)\n",
    "    sums = mult.sum()\n",
    "\n",
    "    print(sums)\n",
    "    return(sums)\n",
    "\n",
    "SEEPSfull(contingency1)\n",
    "SEEPSfull(contingency2)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variogram Scoring Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starting with 1 dimensional data\n",
    "#1 dimensional normal not great for variograms distances.\n",
    "data_normaltrue = norm.rvs(size=1000, loc=0, scale = 1)\n",
    "data_normalpred = norm.rvs(size=1000, loc=0, scale = 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97915165, 1.02788646, 0.951775  , 0.94451351, 0.91145641,\n",
       "       0.95575054, 0.97301219, 1.01818892, 0.99139775, 0.95573447])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Need to look at lag vs covariance \n",
    "#lag for distance or time spatial patterns\n",
    "#also covariance for spatial covariance patterns\n",
    "\n",
    "\n",
    "#lag 10?\n",
    "def variogram_score(observed, predictions, lag=10):\n",
    "    variogramobserved = compute_variogram(observed, observed, lag)\n",
    "    variogrampredicted = compute_variogram(predictions, predictions, lag)\n",
    "    score = np.sum((variogramobserved - variogrampredicted) ** 2)\n",
    "    print(score)\n",
    "    return score\n",
    "\n",
    "\n",
    "def compute_variogram(observed, unused, lag):\n",
    "    n = len(observed)\n",
    "    variogram = []\n",
    "    for h in range(1, lag + 1):\n",
    "        totaldifs = 0\n",
    "        count = 0\n",
    "        for i in range(n - h):\n",
    "            #half squared distance\n",
    "            totaldifs += 0.5 * (observed[i] - observed[i + h]) ** 2\n",
    "            count += 1\n",
    "        # Average variogram for the given lag\n",
    "        variogram.append(totaldifs / count)\n",
    "    \n",
    "    #print(variogram)\n",
    "    return np.array(variogram)\n",
    "\n",
    "compute_variogram(data_normaltrue,data_normaltrue, 10)\n",
    "\n",
    "#As all just normal instances, changing the lag doesn't change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19257717498170174\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "# Calculate the variogram score\n",
    "score = variogram_score(data_normaltrue, data_normalpred, lag=10)\n",
    "#closer to zero is better\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using covariance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
