{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sigkernel\n",
    "import Cython\n",
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The example given just doesn't work??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3949, device='cuda:0', dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "tensor(0.3949, device='cuda:0', dtype=torch.float64, grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "static_kernel = sigkernel.RBFKernel(sigma=0.5)\n",
    "dyadic_order = 1\n",
    "max_batch = 100\n",
    "signature_kernel = sigkernel.SigKernel(static_kernel, dyadic_order)\n",
    "\n",
    "batch, len_x, len_y, dim = 2, 3, 4, 2\n",
    "X = torch.rand((batch,len_x,dim), dtype=torch.float64, device='cuda',requires_grad=True) # shape (batch,len_x,dim)\n",
    "Y = torch.rand((batch,len_y,dim), dtype=torch.float64, device='cuda') # shape (batch,len_y,dim)\n",
    "Z = torch.rand((batch,len_x,dim), dtype=torch.float64, device='cuda') # shape (batch,len_y,dim)\n",
    "\n",
    "K=signature_kernel.compute_kernel(X,Y,max_batch)\n",
    "G = signature_kernel.compute_Gram(X,Y,max_batch)\n",
    "mmd = signature_kernel.compute_mmd(X,Y,max_batch)\n",
    "print(mmd)\n",
    "mmd.backward()\n",
    "print(mmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Compute scoring rule between X and a sample path y, i.e. S_sig(X,y) = E[k(X,X)] - 2E[k(X,y] ...\u001b[39;00m\n\u001b[0;32m     31\u001b[0m y \u001b[38;5;241m=\u001b[39m Y[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 32\u001b[0m sr \u001b[38;5;241m=\u001b[39m \u001b[43msignature_kernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_scoring_rule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmax_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# ... and expected scoring rule between X and Y, i.e. S(X,Y) = E_Y[S_sig(X,y)]\u001b[39;00m\n\u001b[0;32m     35\u001b[0m esr \u001b[38;5;241m=\u001b[39m signature_kernel\u001b[38;5;241m.\u001b[39mcompute_expected_scoring_rule(X,Y,max_batch)\n",
      "File \u001b[1;32mc:\\Users\\arche\\anaconda3\\envs\\Diss\\Lib\\site-packages\\sigkernel\\sigkernel.py:156\u001b[0m, in \u001b[0;36mSigKernel.compute_scoring_rule\u001b[1;34m(self, X, y, max_batch)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m y\u001b[38;5;241m.\u001b[39mrequires_grad, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe second input should not require grad\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m K_XX \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_Gram(X, X, sym\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_batch\u001b[38;5;241m=\u001b[39mmax_batch)\n\u001b[1;32m--> 156\u001b[0m K_Xy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_Gram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msym\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m K_XX_m \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39msum(K_XX) \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39mdiag(K_XX))) \u001b[38;5;241m/\u001b[39m (K_XX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m (K_XX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.\u001b[39m))\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K_XX_m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2.\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(K_Xy)\n",
      "File \u001b[1;32mc:\\Users\\arche\\anaconda3\\envs\\Diss\\Lib\\site-packages\\sigkernel\\sigkernel.py:102\u001b[0m, in \u001b[0;36mSigKernel.compute_Gram\u001b[1;34m(self, X, Y, sym, max_batch)\u001b[0m\n\u001b[0;32m    100\u001b[0m batch_Y \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_X \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_batch \u001b[38;5;129;01mand\u001b[39;00m batch_Y \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_batch:\n\u001b[1;32m--> 102\u001b[0m     K \u001b[38;5;241m=\u001b[39m \u001b[43m_SigKernelGram\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatic_kernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdyadic_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msym\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_naive_solver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m batch_X \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_batch \u001b[38;5;129;01mand\u001b[39;00m batch_Y \u001b[38;5;241m>\u001b[39m max_batch:\n\u001b[0;32m    104\u001b[0m     cutoff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(batch_Y\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\arche\\anaconda3\\envs\\Diss\\Lib\\site-packages\\torch\\autograd\\function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    583\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\arche\\anaconda3\\envs\\Diss\\Lib\\site-packages\\sigkernel\\sigkernel.py:352\u001b[0m, in \u001b[0;36m_SigKernelGram.forward\u001b[1;34m(ctx, X, Y, static_kernel, dyadic_order, sym, _naive_solver)\u001b[0m\n\u001b[0;32m    349\u001b[0m NN \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdyadic_order)\u001b[38;5;241m*\u001b[39m(N\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# computing dsdt k(X^i_s,Y^j_t)\u001b[39;00m\n\u001b[1;32m--> 352\u001b[0m G_static \u001b[38;5;241m=\u001b[39m \u001b[43mstatic_kernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGram_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m G_static_ \u001b[38;5;241m=\u001b[39m G_static[:, :, \u001b[38;5;241m1\u001b[39m:, \u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m+\u001b[39m G_static[:, :, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m G_static[:, :, \u001b[38;5;241m1\u001b[39m:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m G_static[:, :, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    354\u001b[0m G_static_ \u001b[38;5;241m=\u001b[39m tile(tile(G_static_, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdyadic_order)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdyadic_order), \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdyadic_order)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdyadic_order)\n",
      "File \u001b[1;32mc:\\Users\\arche\\anaconda3\\envs\\Diss\\Lib\\site-packages\\sigkernel\\static_kernels.py:70\u001b[0m, in \u001b[0;36mRBFKernel.Gram_matrix\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m     68\u001b[0m N \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     69\u001b[0m Xs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(X\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 70\u001b[0m Ys \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2.\u001b[39m\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mipk,jqk->ijpq\u001b[39m\u001b[38;5;124m'\u001b[39m, X, Y)\n\u001b[0;32m     72\u001b[0m dist \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(Xs,(A,\u001b[38;5;241m1\u001b[39m,M,\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(Ys,(\u001b[38;5;241m1\u001b[39m,B,\u001b[38;5;241m1\u001b[39m,N))\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "# Specify the static kernel (for linear kernel use sigkernel.LinearKernel())\n",
    "static_kernel = sigkernel.RBFKernel(sigma=0.5)\n",
    "\n",
    "# Specify dyadic order for PDE solver (int > 0, default 0, the higher the more accurate but slower)\n",
    "dyadic_order = 1\n",
    "\n",
    "# Specify maximum batch size of computation; if memory is a concern try reducing max_batch, default=100\n",
    "max_batch = 100\n",
    "\n",
    "# Initialize the corresponding signature kernel\n",
    "signature_kernel = sigkernel.SigKernel(static_kernel, dyadic_order)\n",
    "\n",
    "# Synthetic data\n",
    "batch, len_x, len_y, dim = 5, 10, 20, 2\n",
    "X = torch.rand((batch,len_x,dim), dtype=torch.float64, device='cuda', requires_grad=True) # shape (batch,len_x,dim)\n",
    "Y = torch.rand((batch,len_y,dim), dtype=torch.float64, device='cuda') # shape (batch,len_y,dim)\n",
    "Z = torch.rand((batch,len_x,dim), dtype=torch.float64, device='cuda') # shape (batch,len_y,dim)\n",
    "\n",
    "# Compute signature kernel \"batch-wise\" (i.e. k(x_1,y_1),...,k(x_batch, y_batch))\n",
    "K = signature_kernel.compute_kernel(X,Y,max_batch)\n",
    "\n",
    "# Compute signature kernel Gram matrix (i.e. k(x_i,y_j) for i,j=1,...,batch), also works for different batch_x != batch_y)\n",
    "G = signature_kernel.compute_Gram(X,Y,max_batch)\n",
    "\n",
    "# Compute MMD distance between samples x ~ X and samples y ~ Y, where X,Y are two distributions on path space...\n",
    "mmd = signature_kernel.compute_mmd(X,Y,max_batch)\n",
    "# ... and to backpropagate through the MMD distance simply call .backward(), like any other PyTorch loss function\n",
    "mmd.backward()\n",
    "\n",
    "# Compute scoring rule between X and a sample path y, i.e. S_sig(X,y) = E[k(X,X)] - 2E[k(X,y] ...\n",
    "y = Y[0]\n",
    "sr = signature_kernel.compute_scoring_rule(X,y,max_batch)\n",
    "\n",
    "# ... and expected scoring rule between X and Y, i.e. S(X,Y) = E_Y[S_sig(X,y)]\n",
    "esr = signature_kernel.compute_expected_scoring_rule(X,Y,max_batch)\n",
    "\n",
    "# Sig CHSIC: XY|Z\n",
    "sigchsic = signature_kernel.SigCHSIC(X, Y, Z, static_kernel, dyadic_order=1, eps=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Compute scoring rule between X and a sample path y, i.e. S_sig(X,y) = E[k(X,X)] - 2E[k(X,y] ...\u001b[39;00m\n\u001b[0;32m     34\u001b[0m y \u001b[38;5;241m=\u001b[39m Y[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 35\u001b[0m sr \u001b[38;5;241m=\u001b[39m \u001b[43msignature_kernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_scoring_rule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmax_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# ... and expected scoring rule between X and Y, i.e. S(X,Y) = E_Y[S_sig(X,y)]\u001b[39;00m\n\u001b[0;32m     38\u001b[0m esr \u001b[38;5;241m=\u001b[39m signature_kernel\u001b[38;5;241m.\u001b[39mcompute_expected_scoring_rule(X,Y,max_batch)\n",
      "File \u001b[1;32mc:\\Users\\arche\\anaconda3\\envs\\Diss\\Lib\\site-packages\\sigkernel\\sigkernel.py:156\u001b[0m, in \u001b[0;36mSigKernel.compute_scoring_rule\u001b[1;34m(self, X, y, max_batch)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m y\u001b[38;5;241m.\u001b[39mrequires_grad, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe second input should not require grad\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m K_XX \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_Gram(X, X, sym\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_batch\u001b[38;5;241m=\u001b[39mmax_batch)\n\u001b[1;32m--> 156\u001b[0m K_Xy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_Gram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msym\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m K_XX_m \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39msum(K_XX) \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39mdiag(K_XX))) \u001b[38;5;241m/\u001b[39m (K_XX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m (K_XX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.\u001b[39m))\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K_XX_m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2.\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(K_Xy)\n",
      "File \u001b[1;32mc:\\Users\\arche\\anaconda3\\envs\\Diss\\Lib\\site-packages\\sigkernel\\sigkernel.py:102\u001b[0m, in \u001b[0;36mSigKernel.compute_Gram\u001b[1;34m(self, X, Y, sym, max_batch)\u001b[0m\n\u001b[0;32m    100\u001b[0m batch_Y \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_X \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_batch \u001b[38;5;129;01mand\u001b[39;00m batch_Y \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_batch:\n\u001b[1;32m--> 102\u001b[0m     K \u001b[38;5;241m=\u001b[39m \u001b[43m_SigKernelGram\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatic_kernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdyadic_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msym\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_naive_solver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m batch_X \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_batch \u001b[38;5;129;01mand\u001b[39;00m batch_Y \u001b[38;5;241m>\u001b[39m max_batch:\n\u001b[0;32m    104\u001b[0m     cutoff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(batch_Y\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\arche\\anaconda3\\envs\\Diss\\Lib\\site-packages\\torch\\autograd\\function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    583\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\arche\\anaconda3\\envs\\Diss\\Lib\\site-packages\\sigkernel\\sigkernel.py:352\u001b[0m, in \u001b[0;36m_SigKernelGram.forward\u001b[1;34m(ctx, X, Y, static_kernel, dyadic_order, sym, _naive_solver)\u001b[0m\n\u001b[0;32m    349\u001b[0m NN \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdyadic_order)\u001b[38;5;241m*\u001b[39m(N\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# computing dsdt k(X^i_s,Y^j_t)\u001b[39;00m\n\u001b[1;32m--> 352\u001b[0m G_static \u001b[38;5;241m=\u001b[39m \u001b[43mstatic_kernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGram_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m G_static_ \u001b[38;5;241m=\u001b[39m G_static[:, :, \u001b[38;5;241m1\u001b[39m:, \u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m+\u001b[39m G_static[:, :, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m G_static[:, :, \u001b[38;5;241m1\u001b[39m:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m G_static[:, :, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    354\u001b[0m G_static_ \u001b[38;5;241m=\u001b[39m tile(tile(G_static_, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdyadic_order)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdyadic_order), \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdyadic_order)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdyadic_order)\n",
      "File \u001b[1;32mc:\\Users\\arche\\anaconda3\\envs\\Diss\\Lib\\site-packages\\sigkernel\\static_kernels.py:70\u001b[0m, in \u001b[0;36mRBFKernel.Gram_matrix\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m     68\u001b[0m N \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     69\u001b[0m Xs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(X\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 70\u001b[0m Ys \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2.\u001b[39m\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mipk,jqk->ijpq\u001b[39m\u001b[38;5;124m'\u001b[39m, X, Y)\n\u001b[0;32m     72\u001b[0m dist \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(Xs,(A,\u001b[38;5;241m1\u001b[39m,M,\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(Ys,(\u001b[38;5;241m1\u001b[39m,B,\u001b[38;5;241m1\u001b[39m,N))\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sigkernel\n",
    "\n",
    "# Specify the static kernel (for linear kernel use sigkernel.LinearKernel())\n",
    "static_kernel = sigkernel.RBFKernel(sigma=0.5)\n",
    "\n",
    "# Specify dyadic order for PDE solver (int > 0, default 0, the higher the more accurate but slower)\n",
    "dyadic_order = 1\n",
    "\n",
    "# Specify maximum batch size of computation; if memory is a concern try reducing max_batch, default=100\n",
    "max_batch = 100\n",
    "\n",
    "# Initialize the corresponding signature kernel\n",
    "signature_kernel = sigkernel.SigKernel(static_kernel, dyadic_order)\n",
    "\n",
    "# Synthetic data\n",
    "batch, len_x, len_y, dim = 5, 10, 20, 2\n",
    "X = torch.rand((batch,len_x,dim), dtype=torch.float64, device='cuda', requires_grad=True) # shape (batch,len_x,dim)\n",
    "Y = torch.rand((batch,len_y,dim), dtype=torch.float64, device='cuda') # shape (batch,len_y,dim)\n",
    "Z = torch.rand((batch,len_x,dim), dtype=torch.float64, device='cuda') # shape (batch,len_y,dim)\n",
    "\n",
    "# Compute signature kernel \"batch-wise\" (i.e. k(x_1,y_1),...,k(x_batch, y_batch))\n",
    "K = signature_kernel.compute_kernel(X,Y,max_batch)\n",
    "\n",
    "# Compute signature kernel Gram matrix (i.e. k(x_i,y_j) for i,j=1,...,batch), also works for different batch_x != batch_y)\n",
    "G = signature_kernel.compute_Gram(X,Y,max_batch)\n",
    "\n",
    "# Compute MMD distance between samples x ~ X and samples y ~ Y, where X,Y are two distributions on path space...\n",
    "mmd = signature_kernel.compute_mmd(X,Y,max_batch)\n",
    "# ... and to backpropagate through the MMD distance simply call .backward(), like any other PyTorch loss function\n",
    "mmd.backward()\n",
    "\n",
    "# Compute scoring rule between X and a sample path y, i.e. S_sig(X,y) = E[k(X,X)] - 2E[k(X,y] ...\n",
    "y = Y[0]\n",
    "sr = signature_kernel.compute_scoring_rule(X,y,max_batch)\n",
    "\n",
    "# ... and expected scoring rule between X and Y, i.e. S(X,Y) = E_Y[S_sig(X,y)]\n",
    "esr = signature_kernel.compute_expected_scoring_rule(X,Y,max_batch)\n",
    "\n",
    "# Sig CHSIC: XY|Z\n",
    "sigchsic = signature_kernel.SigCHSIC(X, Y, Z, static_kernel, dyadic_order=1, eps=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Diss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
